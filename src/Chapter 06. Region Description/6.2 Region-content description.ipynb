{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 6.2 Region-content description\n",
    "\n",
    "Unlike shape description techniques, which work with regions' contours, region-content description focuses on characterizing the content of segmented regions through their distribution in the image, their textures, etc. Regarding textures, it gives us information about the spatial arrangement of color or intensities in an image or selected region of an image. Textures can be used to help in segmentation or classification of images. Notice that these methods doesn't require binary images as input. \n",
    "\n",
    "This notebook covers different region-content description techniques:\n",
    "\n",
    "- 2D image moments (<a href=\"#621\">section 6.2.1</a>)\n",
    "- Hu moments (<a href=\"#622\">section 6.2.2</a>)\n",
    "- Image histogram moments (<a href=\"#6231\">section 6.2.3.1</a>)\n",
    "- Co-ocurrence matrices (<a href=\"#6232\">section 6.2.3.2</a>)\n",
    "\n",
    "\n",
    "## Problem context - Car plates\n",
    "\n",
    "In this notebook, our task is twofold!\n",
    "\n",
    "### Number-plate detection for UMA\n",
    "\n",
    "<center><img src=\"./images/access_system.png\" width=\"400\"></center>$\\\\[5pt]$\n",
    "\n",
    "Basically, we have to continue with our number-plate detection work looking for a way to obtain a feature vector that distinguishes each character in a Spanish car plate. In this notebok we will try more advanced methods, like **image moments** or **Hu moments**.\n",
    "\n",
    "### Identification of the State of a license plate state\n",
    "\n",
    "An American company contacted us for developing a **texture description method** that describes **a license plate according to its State of origin** instead of the characters appearing. As you may know, USA uses a different license plates for each state in the country:$\\\\[5pt]$\n",
    "\n",
    "<center><img src=\"./images/usa_plates.jpg\" width=\"600\"></center>\n",
    "\n",
    "You will use some region description methods applied to this problem like **co-ocurrence matrices** or **image histogram moments**. Again, your task is to develop a method returning a feature vector that allows for the identification of the State of origin of such license plates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = (15.0, 8.0)\n",
    "from scipy import stats \n",
    "\n",
    "images_path = './images/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2.1 Image moments <a id=\"621\"></a>\n",
    "\n",
    "An **image moment** (2D-moment) is the weighted average (or moment) of the intensity of the pixels in the image/region, or a function combining other moments. Moments usually have some attractive property or interpretation, and they can work in both grayscale and color images. For example, when working with 1 dimension (*e.g.* with a histogram), the moment of order 0 represents the number of pixels in the image, while when dealing with 2 dimensions (*e.g.* an image) it represents its area, that is, the number of white pixels (if the image is binary).\n",
    "\n",
    "There are 3 main types of moments:\n",
    "\n",
    "- **Non-central moments:**\n",
    "\n",
    "  $\\hspace{1.2cm}m_{ij} = \\sum_{y=1}^{rows}\\sum_{x=1}^{cols}x^i y^j I(y,x)$\n",
    "  $\\\\[5pt]$\n",
    "   $\\hspace{1.2cm}$where $I(y,x)$ represents the intensity of the pixel in the $(y, x)$ coordinates of image $I$.$\\\\[5pt]$\n",
    "\n",
    "- **Central moments:**\n",
    "\n",
    "  $\\hspace{1.2cm}\\mu_{ij} = \\sum_{y=1}^{rows}\\sum_{x=1}^{cols}(x-\\overline{x})^i (y-\\overline{y})^j I(y,x)$ \n",
    "  $\\\\[5pt]$\n",
    "   $\\hspace{1.2cm}$being $\\left(\\overline{x},\\overline{y}\\right) = \\left(\\frac{m_{10}}{m_{00}} ,\\frac{m_{01}}{m_{00}} \\right)$ the centroid of the region. $\\\\[3pt]$\n",
    " \n",
    "  When dealing with big images/regions, it is possible to save some computation time computing the central moments using the non-central ones:\n",
    "\n",
    "$\n",
    "\\begin{array}{l}\n",
    "\\hspace{2cm}\\mu_{00} = m_{00} \\equiv \\mu \\\\\n",
    "\\hspace{2cm}\\mu_{01} = 0 \\\\\n",
    "\\hspace{2cm}\\mu_{10} = 0 \\\\\n",
    "\\hspace{2cm}\\mu_{20} = m_{20} - \\mu \\overline{x}^2\\\\\n",
    "\\hspace{2cm}\\mu_{11} = m_{11} - \\mu \\overline{x}\\,\\overline{y}\\\\\n",
    "\\hspace{2cm}\\mu_{02} = m_{02} - \\mu \\overline{y}^2\\\\\n",
    "\\hspace{2cm}\\mu_{30} = m_{30} - 3m_{20} \\overline{x} + 2 \\mu \\overline{x}^3 \\\\\n",
    "\\hspace{2cm}\\mu_{21} = m_{21} - m_{20} \\overline{y} - 2m_{11} \\overline{x} + 2\\mu \\overline{x}^2\\overline{y} \\\\\n",
    "\\hspace{2cm}\\mu_{12} = m_{12} - m_{02} \\overline{x} - 2m_{11} \\overline{y} + 2\\mu \\overline{y}^2\\overline{x}\\\\\n",
    "\\hspace{2cm}\\mu_{03} = m_{03} - 3m_{02} \\overline{y} + 2 \\mu \\overline{y}^3\\\\\n",
    "\\end{array}\n",
    "$<br /> <br />\n",
    "$\\hspace{1cm}$In general, the following formula can be used to retrieve an arbitrary central moment: <br /><br />\n",
    "$\\hspace{2cm}\\mu_{pq} = \\sum_m^p \\sum_n^q {p\\choose m}{q\\choose n}(-\\overline{x})^{(p-m)}(-\\overline{y})^{(q-n)}m_{mn}$$\\\\[5pt]$\n",
    "\n",
    "- **Scale invariant moments:**$\\\\[3pt]$<br />\n",
    "Can be built from from central moments by dividing through a properly scaled zero-th central moment:\n",
    "\n",
    "$\\hspace{2cm} \\eta_{ij} = \\mu_{ij}\\ /\\ \\mu_{00}^{1+((i+j)/2)}$\n",
    "\n",
    "$\\hspace{2cm}$ where $i + j \\ge 2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"orange\">OpenCV pill</font>\n",
    "    \n",
    "OpenCV defines a method for computing some central, non-central and scale-invariant moments called [`cv2.moments()`](https://docs.opencv.org/4.2.0/d3/dc0/group__imgproc__shape.html#ga556a180f43cab22649c23ada36a8a139), which gets:\n",
    "\n",
    "- working with intensity images: a contour (array of 2D points) delimiting the segmented regions.\n",
    "- working with grayscale images: the image itself.\n",
    "\n",
    "This function returns a dictionary containing the computed moments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\"><b><i>ASSIGNMENT 1: Computing image moments</i></b></span>**\n",
    "\n",
    "**What to do?** Your first tasks is to complete the method `image_moments()`, which applies the previously mentioned [`cv2.moments()`](https://docs.opencv.org/4.2.0/d3/dc0/group__imgproc__shape.html#ga556a180f43cab22649c23ada36a8a139) to a binary image, for example a thresholded image containing the numbers of a plate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 1\n",
    "def image_moments(region):\n",
    "    \"\"\" Compute moments of the region in a binary image.   \n",
    "    \n",
    "        Args:\n",
    "            region: Binary image\n",
    "                    \n",
    "        Returns: \n",
    "            moments: dictionary containing all moments of the region\n",
    "    \"\"\"   \n",
    "    # Compute moments\n",
    "    moments = cv2.moments(None)\n",
    "    \n",
    "    return moments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the next code to **test if the results are correct**, rounding the output of your `image_moments()` function to have 2 decimals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = np.array([[255,255,255,255,255],[255,0,0,0,255],[255,0,0,255,255],[255,0,255,255,255],[0,0,255,255,255]], dtype=np.uint8)\n",
    "moments = image_moments(region)\n",
    "\n",
    "# Round moments for visualization matters\n",
    "for k, v in moments.items():\n",
    "    moments[None] = round(None,None)\n",
    "\n",
    "print(moments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>**Expected output  </font>**\n",
    "\n",
    "    {'m00': 4335.0, 'm10': 9945.0, 'm01': 8160.0, 'm20': 32895.0, 'm11': 20655.0, 'm02': 24990.0, 'm30': 115515.0, 'm21': 68595.0, 'm12': 65535.0, 'm03': 83130.0, 'mu20': 10080.0, 'mu11': 1935.0, 'mu02': 9630.0, 'mu30': -6199.41, 'mu21': -2203.24, 'mu12': 920.29, 'mu03': -164.12, 'nu20': 0.0, 'nu11': 0.0, 'nu02': 0.0, 'nu30': -0.0, 'nu21': -0.0, 'nu12': 0.0, 'nu03': -0.0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code illustrates the moments retrieved from two toy images containing a square, a corner and a line. As you can see, they show differences, so these moments postulate as good descriptors for differentiating them. \n",
    "\n",
    "Recall some interesting facts: \n",
    "\n",
    "- Number of white pixels in the image (if binary): $m_{00} = \\sum_{y=1}^{rows}\\sum_{x=1}^{cols}I(y,x)$\n",
    "- Centroid: $(\\overline{x},\\overline{y})=(\\frac{m_{10}}{m_{00}}, \\frac{m_{01}}{m_{00}})$\n",
    "- Excentricity: $e=\\frac{(\\mu_{20}-\\mu_{02})^2+4\\mu_{11}^2}{(\\mu_{20}+\\mu_{02})^2}$ *(Ratio of the longest chord and longest perpendicular chord)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_features(moments):\n",
    "    print('\\n'+'Some features:')\n",
    "    # Excentricity\n",
    "    e = ((moments['mu20']-moments['mu02'])**2+4*(moments['mu11']**2))/((moments['mu20']+moments['mu02'])**2)\n",
    "    print('Number of white pixels =',moments['m00']/255)\n",
    "    print('Centroid (x,y) = (',moments['m10']/moments['m00'],',',\n",
    "     moments['m01']/moments['m00'],')')\n",
    "    print('Excentricity e = ', round(e,2), '\\n')\n",
    "    \n",
    "    \n",
    "im_square = np.array([[0,0,0,0],[0,255,255,255],[0,255,255,255],[0,255,255,255]], dtype=np.uint8)\n",
    "im_corner = np.array([[0,255,255,255],[0,255,0,0],[0,255,0,0],[0,255,0,0]], dtype=np.uint8)\n",
    "im_line = np.array([[0,255,0,0],[0,255,0,0],[0,255,0,0],[0,255,0,0]], dtype=np.uint8)\n",
    "\n",
    "moments_square = image_moments(im_square)\n",
    "moments_corner = image_moments(im_corner)\n",
    "moments_line = image_moments(im_line)\n",
    "\n",
    "for k, v in moments_square.items():\n",
    "    moments_square[k] = round(v,2)\n",
    "    \n",
    "for k, v in moments_corner.items():\n",
    "    moments_corner[k] = round(v,2)\n",
    "    \n",
    "for k, v in moments_line.items():\n",
    "    moments_line[k] = round(v,2)    \n",
    "\n",
    "plt.subplot(131)\n",
    "plt.imshow(im_square,cmap='gray')\n",
    "plt.title('Square image')\n",
    "print('Moments square image: ' + str(moments_square))\n",
    "print_features(moments_square)\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.imshow(im_corner,cmap='gray')\n",
    "plt.title('Corner image')\n",
    "print('Moments corner image: ' + str(moments_corner))\n",
    "print_features(moments_corner)\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.imshow(im_line,cmap='gray')\n",
    "plt.title('Line image')\n",
    "print('Moments line image:   ' + str(moments_line))\n",
    "print_features(moments_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Invariance analysis \n",
    "\n",
    "Image moments could be good descriptors for addressing the problem posed by UMA. We could compute the moments of a segment region and use them as feature vector $\\mathbf{x}=[x_1,\\dots,x_n]^T$. Also, as $i$ and $j$ in the previous equations can take any integer, we could have a feature vector of any desired length. For example, if you design a region descriptor system that considers the first three non-central, central, and scale invariant moments, you will use: $\\mathbf{x}=[m_{00},m_{10},m_{01},\\mu_{20},\\mu_{11},\\mu_{02},\\eta_{20},\\eta_{11},\\eta_{02}]^T$.\n",
    "\n",
    "In the context of the number-plate detection problem, the results have to be (at least) position and scale invariants, because a car could stop closer or further away from the camera and in different positions (rotation is not that important).\n",
    "\n",
    "To check if these moments have such invariances, you are going to compute the moments of a region, as well as of a scaled and rotated versions of it. To visually check the results, we are going to use bar charts, showing the moments for the original, rotated and scaled images, which should look like this:\n",
    "\n",
    "<center><img src=\"./images/moments.png\" width=\"800\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\"><b><i>ASSIGNMENT 2: Checking invariances</i></b></span>**\n",
    "\n",
    "Complete the method `compare_moments()`, which takes:\n",
    "- a list of labels for the bar chart, and \n",
    "- three lists containing the moments of a region, and its rotated and scaled versions. \n",
    "These methods, using said arguments, plots the chart bar previously showed.\n",
    "\n",
    "For the plot you can use `plt.bar(labels,values)`, where `labels` is a list of strings (e.g. `keys` of the dictionary of moments) and `values` a list of numbers (e.g. `values` of such dictionary). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 2\n",
    "def compare_moments(labels, moments, moments_rotated, moments_scaled):\n",
    "    \"\"\" Plot a bar chart comparing the three input moment arrays  \n",
    "    \n",
    "        Args:\n",
    "            labels: Labels of the bar chart\n",
    "            moments: list containing moments of a original region\n",
    "            moments_rotated: list containing moments of the original region, but previously rotated\n",
    "            moments_scaled: list containing moments of the original region, but previously scaled\n",
    "    \"\"\" \n",
    "    \n",
    "    # Show original moments\n",
    "    plt.subplot(131)\n",
    "    plt.title(\"Original\")\n",
    "    plt.bar(None,None)\n",
    "\n",
    "    # Show rotated moments\n",
    "    plt.subplot(132)\n",
    "    plt.title(\"Rotated\")\n",
    "    plt.bar(None,None)\n",
    "\n",
    "    # Show scaled moments\n",
    "    plt.subplot(133)\n",
    "    plt.title(\"Scaled\")\n",
    "    plt.bar(None,None) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to separately analyze the invariance of:\n",
    "- the **non-central** (first 10 values of moment dictionary), \n",
    "- **central** (following 7), and \n",
    "- **scale-invariant** (last 7) moments. \n",
    "\n",
    "*Take a look at the result of the previous assignment to check this!*\n",
    "\n",
    "First, let's compute the moments from an initial image, a rotated version of it (90 degrees), and a scaled version (by a factor of 2 in both horizontal and vertical axes). Finally show those images.\n",
    "\n",
    "*Hint: You can rotate a numpy array using [`np.rot90()`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.rot90.html) and scale an image using [`cv2.resize()`](https://docs.opencv.org/4.2.0/da/d54/group__imgproc__transform.html#ga47a974309e9102f5f08231edc7e7529d), although there are many more options.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read binary image and compute moments\n",
    "region = cv2.imread(images_path + 'region_6.png',0)\n",
    "moments = image_moments(None)\n",
    "\n",
    "# Rotate image and compute moments\n",
    "region_rotated = np.rot90(None)\n",
    "moments_rotated = image_moments(None)\n",
    "\n",
    "# Resize image and compute moments\n",
    "region_scaled = cv2.resize(None, dsize=None, fx=None, fy=None) # keep the dsize=None\n",
    "moments_scaled = image_moments(None)\n",
    "\n",
    "# Show the initial image\n",
    "plt.subplot(131)\n",
    "plt.title('Initial image')\n",
    "plt.imshow(None, None')\n",
    "\n",
    "# Show the rotated version\n",
    "plt.subplot(132)\n",
    "plt.title('Rotated version')\n",
    "plt.imshow(None, None)\n",
    "\n",
    "# Show the scaled version\n",
    "plt.subplot(133)\n",
    "plt.title('Scaled version')\n",
    "plt.imshow(None, None);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's start comparing the **Non-central moments** of the three images! *Hint: pay special attention to the scale of the axes in the plot!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results for non-central moments\n",
    "labels = list(moments.keys())[:None]\n",
    "non_central_moments = list(moments.values())[:None]\n",
    "non_central_rotated = list(moments_rotated.values())[:None]\n",
    "non_central_scaled = list(moments_scaled.values())[:None]\n",
    "\n",
    "compare_moments(None,None,None,None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"><b><i>Thinking about it (1)</i></b></font>\n",
    "\n",
    "Now, **answer the following questions:**\n",
    "\n",
    "- Are these moments invariant to rotation?\n",
    "\n",
    "    <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>Your answer here!</i></p>\n",
    "    \n",
    "- Are these moments invariant to scale?\n",
    "\n",
    "    <p style=\"margin: 4px 0px 0px 5px; color:blue\"><i>Your answer here!</i></p>   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's continue with **central moments**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results for central moments\n",
    "\n",
    "labels = list(moments.keys())[None:None]\n",
    "central_moments = list(moments.values())[None:None]\n",
    "central_rotated = list(moments_rotated.values())[None:None]\n",
    "central_scaled = list(moments_scaled.values())[None:None]\n",
    "\n",
    "compare_moments(None,None,None,None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"><b><i>Thinking about it (2)</i></b></font>\n",
    "\n",
    "Now, **answer the following questions:**\n",
    "\n",
    "- Are these moments invariant to rotation?\n",
    "\n",
    "    <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>Your answer here!</i></p>\n",
    "    \n",
    "- Are these moments invariant to scale?\n",
    "\n",
    "    <p style=\"margin: 4px 0px 0px 5px; color:blue\"><i>Your answer here!</i></p>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we conclude with **scale-invariant moments**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results for scale-invariant moments\n",
    "\n",
    "labels = list(moments.keys())[None:]\n",
    "invariant_moments = list(moments.values())[None:]\n",
    "invariant_rotated = list(moments_rotated.values())[None:]\n",
    "invariant_scaled = list(moments_scaled.values())[None:]\n",
    "\n",
    "compare_moments(None,None,None,None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"><b><i>Thinking about it (3)</i></b></font>\n",
    "\n",
    "Now, **answer the following questions:**\n",
    "\n",
    "- Are these moments invariant to rotation?\n",
    "\n",
    "    <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>Your answer here!</i></p>\n",
    "    \n",
    "- Are these moments invariant to scale?\n",
    "\n",
    "    <p style=\"margin: 4px 0px 0px 5px; color:blue\"><i>Your answer here!</i></p>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2.2 Hu moments <a id=\"622\"></a>\n",
    "\n",
    "The **Hu moments** (published in 1962 by Ming-Kuei Hu) are a set of 7 particular moments showing **interesting invariance properties**. They are calculated using scale-invariant ones:\n",
    "\n",
    "$\n",
    "\\begin{array}{l}\n",
    "\\hspace{2cm}v_{1} = \\eta_{20} + \\eta_{02} \\\\\n",
    "\\hspace{2cm}v_{2} = (\\eta_{20} - \\eta_{02}) + 4\\eta_{11}^2 \\\\\n",
    "\\hspace{2cm}v_{3} = (\\eta_{20} - 3\\eta_{12})^2 + (3\\eta_{21} - \\eta_{03})^2 \\\\\n",
    "\\hspace{2cm}v_{4} = (\\eta_{30} + \\eta_{12})^2 + (\\eta_{21} + \\eta_{03})^2\\\\\n",
    "\\hspace{2cm}v_{5} = (\\eta_{30}-3\\eta_{12})(\\eta_{30}+\\eta_{12})[(\\eta_{30}+\\eta_{12})^2 -3(\\eta_{21}+\\eta_{03})^2] + (3\\eta_{21}-\\eta_{03})(\\eta_{21}+\\eta_{03})[3(\\eta_{30}+\\eta_{12})^2-(\\eta_{21} + \\eta_{03})^2]\\\\\n",
    "\\hspace{2cm}v_{6} = (\\eta_{20}-\\eta_{02})[(\\eta_{30}+\\eta_{12})^2 -(\\eta_{21}-\\eta_{03})^2 + 4\\eta_{11} (\\eta_{30}+\\eta_{12})(\\eta_{21}+\\eta_{03})] \\\\\n",
    "\\hspace{2cm}v_{7} = (3\\eta_{21}-\\eta_{03})(\\eta_{30}+\\eta_{12})[(\\eta_{30}+\\eta_{12})^2-3(\\eta_{30}+\\eta_{12})^2]+(\\eta_{30}-3\\eta_{12})(\\eta_{21}+\\eta_{03})[3(\\eta_{30}+\\eta_{12})^2-(\\eta_{21}+\\eta_{03})^2]\\\\\n",
    "\\end{array}\n",
    "$\n",
    "\n",
    "being:\n",
    "$ \n",
    "\\eta_{pq} = \\frac{\\mu_{pq}}{\\mu^\\gamma_{00}} \\, \\, \\, \\, \\,  \\gamma = \\frac{p+q}{2}+1\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"orange\">OpenCV pill</font>\n",
    "\n",
    "OpenCV provides a method to retrieve the Hu moments, called (wait for it...) [`cv2.HuMoments()`](https://docs.opencv.org/4.2.0/d3/dc0/group__imgproc__shape.html#gab001db45c1f1af6cbdbe64df04c4e944)!. This method takes as input the dictionary of moments returned by `cv2.moments`. Recall that the scale-invariant moments used for their computation are the `nuij` moments in the dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\"><b><i>ASSIGNMENT 3: Exploring Hu moments invariances</i></b></span>**\n",
    "\n",
    "Previously, we tested the invariances of non-central, central and scale-invariant moments. Now, **we are interested in checking the invariances of the Hu moments**, so we can verify if they are more suitable for the UMA parking problem. \n",
    "\n",
    "For that, use your brand-new `compare_moments()` function in the same way as in the previous exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 3\n",
    "\n",
    "# Read binary image and compute Hu moments\n",
    "region = cv2.imread(images_path + 'region_J.png',0)\n",
    "moments = image_moments(None)\n",
    "hu = cv2.HuMoments(None)\n",
    "\n",
    "# Rotate image and compute Hu moments\n",
    "region_rotated = np.rot90(None)\n",
    "moments_rotated = image_moments(None)\n",
    "hu_rotated = cv2.HuMoments(None)\n",
    "\n",
    "# Resize image and compute Hu moments\n",
    "region_scaled = cv2.resize(None, dsize=None, fx=None, fy=None) # keep the dsize=None\n",
    "moments_scaled = image_moments(None)\n",
    "hu_scaled = cv2.HuMoments(None)\n",
    "\n",
    "\n",
    "# Compare results for Hu moments\n",
    "labels = [\"hu1\",\"hu2\",\"hu3\",\"hu4\",\"hu5\",\"hu6\",\"hu7\"]\n",
    "hu_moments = hu.flatten()\n",
    "hu_rotated = hu_rotated.flatten()\n",
    "hu_scaled = hu_scaled.flatten()\n",
    "\n",
    "compare_moments(None,None,None,None)\n",
    "\n",
    "print('hu_moments:' + str(hu_moments))\n",
    "print('hu_rotated:' + str(hu_rotated))\n",
    "print('hu_scaled: ' + str(hu_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"><b><i>Thinking about it (4)</i></b></font>\n",
    "\n",
    "Now, **answer the following questions:**\n",
    "\n",
    "- Are these moments invariant to rotation?\n",
    "\n",
    "    <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>Your answer here!</i></p>\n",
    "    \n",
    "- Are these moments invariant to scale?\n",
    "\n",
    "    <p style=\"margin: 4px 0px 0px 5px; color:blue\"><i>Your answer here!</i></p>  \n",
    "    \n",
    "- Now that you can deal with different ways to describe a binary region, **what descriptor would you use** for the UMA parking problem? **Why?**\n",
    "\n",
    "    <p style=\"margin: 4px 0px 0px 5px; color:blue\"><i>Your answer here!</i></p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2.3 Texture \n",
    "\n",
    "The previous techniques are useful for describing the distribution of the regions over the image. There is another brunch of algorithms that pursuit the description of regions by **characterizing the texture of the pixels they enclose**. Such methods measure the spatial arrangement of the colors/intensities in a region, providing information about their smoothness, coarseness, and regularity. In this way, if a region does not present changes in intensity, we say that it is a untextured region.\n",
    "\n",
    "<center><img src=\"./images/examples_of_different_textures.png\"  width=\"700\"/></center>\n",
    "\n",
    "Usually, texture descriptors have spatial (position, orientation and scale) and radiometric (contrast and brightness) invariance. We are going to explore two of these descriptors:\n",
    "\n",
    "- 1D moments of the histogram, and\n",
    "- Gray Level Co-Occurrence Matrix (GLCM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.3.1 1D moments of histogram <a id=\"6231\"></a>\n",
    "\n",
    "The **central moments of the histogram** of the pixels within a region statistically describes the frequency of their intensities. They permit us to compactly describe the region through a feature vector containing a few features. They are computed using the equation: $\\\\[5pt]$\n",
    "\n",
    "$\\hspace{2cm} \\mu_n = \\sum_{i=0}^{255} (z_i - \\overline{z})^n h(z_i)$\n",
    "\n",
    "where $h(z_i)$ represents the value stored in the histogram $h(\\cdot)$ for the intensity $z_i$. Keep in mind that:\n",
    "\n",
    "$\n",
    "\\begin{array}{l}\n",
    "\\hspace{2cm} \\mu_0: \\text{number of pixels (1 if normalized)} \\\\\n",
    "\\hspace{2cm} \\mu_1 = 0 \\\\ \n",
    "\\hspace{2cm} \\mu_2: \\text{variance (contrast)} \\\\\n",
    "\\hspace{2cm} \\mu_3: \\text{histogram skew} \\\\\n",
    "\\hspace{2cm} \\mu_4: \\text{histogram uniformity} \\\\\n",
    "\\end{array}\n",
    "$\n",
    "\n",
    "However, they have a serious drawback: they don't encode pattern structures, so different textures may have similar histograms:\n",
    "\n",
    "<center><img src=\"./images/patterns.png\"/></center>\n",
    "\n",
    "Nevertheless, they can be a good option depending on the application, so do not underestimate them!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\"><b><i>ASSIGNMENT 4: Analyizing histograms</i></b></span>**\n",
    "\n",
    "In order to play a bit with these moments, we move to our second application: the state recognition in USA car plates. Two examples of such license plates: $\\\\[12pt]$\n",
    "\n",
    "<center>\n",
    "    <img src=\"./images/idaho.jpg\" width=\"300\" />\n",
    "    <img src=\"./images/nevada.jpg\" width=\"300\" /> \n",
    "    <figcaption>Two examples of USA car plates</figcaption>\n",
    "</center>\n",
    "\n",
    "As we can see, the main difference between them is the texture in the plate background, as each state has a different one. Let's try 1D moments of the histogram for describing those textures!\n",
    "\n",
    "**Your first task** is to plot the histogram of the previous images: `nevada.jpg` and `hawaii.jpg`, and check if the shape of the histograms is enough to differentiate them. *Hint: recall the [`np.ravel()`](https://numpy.org/doc/stable/reference/generated/numpy.ravel.html) function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 4\n",
    "\n",
    "# Read images\n",
    "nevada = cv2.imread(images_path + 'nevada.jpg',0)\n",
    "hawaii = cv2.imread(images_path + 'hawaii.jpg',0)\n",
    "\n",
    "# Show first one histogram\n",
    "plt.subplot(121)\n",
    "plt.title(\"Nevada plate\")\n",
    "plt.hist(None,None,[None,None]) \n",
    "\n",
    "# And the second one!\n",
    "plt.subplot(122)\n",
    "plt.title(\"Hawaii plate\")\n",
    "plt.hist(None,None,[None,None]) \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's complete the method `histogram_moments()` that implements the retrieval of the central moments of the histogram shown above. This method takes as input:\n",
    "\n",
    "- an image, and \n",
    "- the number of moments to be calculated\n",
    "\n",
    "and returns an array containing those moments of the image's histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_moments(image,k):\n",
    "    \"\"\" Compute central moments of the histogram of an image.   \n",
    "    \n",
    "        Args:\n",
    "            image: input image\n",
    "            k: number of moments to compute\n",
    "                    \n",
    "        Returns: \n",
    "            histogram_moments: array containing the histogram moments\n",
    "    \"\"\"   \n",
    "    \n",
    "    \n",
    "    # Compute histogram\n",
    "    hist = cv2.calcHist([image],[0],None,[256],[0,256]) # Keep the None in this function!\n",
    "\n",
    "    # Compute mean average intensity/brightness of the image\n",
    "    z_mean = np.dot(hist[hist.nonzero()[0]].flatten(),hist.nonzero()[0].flatten())/hist[hist.nonzero()[0]].sum()\n",
    "    \n",
    "    # Compute moments\n",
    "    histogram_moments = np.zeros(k)\n",
    "    for i in range(k):\n",
    "        moment = 0.0\n",
    "        for z in range(1,256):            \n",
    "            moment += float(None-None)**None * float(None)        \n",
    "            \n",
    "        histogram_moments[i] = moment/hist.sum()\n",
    "        \n",
    "        # The previous code could be replaced by just one line!\n",
    "        # histogram_moments[i] = np.average((np.arange(1,256) - z_mean)**i, weights = hist[1:256].flatten())\n",
    "    \n",
    "    return(histogram_moments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the next code to **test if the results are correct**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.array([[10,60,20],[60,22,74],[72,132,2]], dtype=np.uint8)\n",
    "\n",
    "moments = histogram_moments(image,6)\n",
    "\n",
    "print(moments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>**Expected output: </font>**\n",
    "\n",
    "    [1.00000000e+00 0.00000000e+00 1.50795062e+03 3.83609108e+04 6.08670794e+06 3.62329032e+08]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Invariance analysis\n",
    "\n",
    "Now that we can obtain the first `k` moments of an image histogram, we are going to see if this method is invariant to scale and rotation. As in the UMA parking problem, our solution must be scale invariant, so let's check if it is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\"><b><i>ASSIGNMENT 5: Checking the invariance of 1D moments</i></b></span>**\n",
    "\n",
    "**What to do?** Check if **the first six 1D moments** of the histogram of an image, a rotated version of it, and a scaled version, are the same. Use [`np.array_equal()`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.array_equal.html) for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 5\n",
    "\n",
    "# Read image and compute histogram moments\n",
    "image = cv2.imread(images_path + 'hawaii.jpg',0)\n",
    "moments = histogram_moments(None,6)\n",
    "\n",
    "# Rotate image and compute histogram moments\n",
    "image_rotated = np.rot90(None)\n",
    "moments_rotated = histogram_moments(None,6)\n",
    "    \n",
    "# Resize image and compute histogram moments\n",
    "image_scaled = cv2.resize(None, dsize=None, fx=None, fy=None) # keep the dsize=None\n",
    "moments_scaled = histogram_moments(None,6)\n",
    "\n",
    "# Compare results\n",
    "print(\"Rotation invariance: \", np.array_equal(None,None))\n",
    "print(\"Scale invariance: \", np.array_equal(None,None))\n",
    "\n",
    "# Show the initial image\n",
    "plt.subplot(131)\n",
    "plt.title('Initial image')\n",
    "plt.imshow(image, cmap='gray')\n",
    "\n",
    "# Show the rotated version\n",
    "plt.subplot(132)\n",
    "plt.title('Rotated version')\n",
    "plt.imshow(image_rotated, cmap='gray')\n",
    "\n",
    "# Show the scaled version\n",
    "plt.subplot(133)\n",
    "plt.title('Scaled version')\n",
    "plt.imshow(image_scaled, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"><b><i>Thinking about it (5)</i></b></font>\n",
    "\n",
    "Now, **answer the following questions:**\n",
    "\n",
    "- Is it invariant to rotation? If not, how can we turn this method into it?\n",
    "\n",
    "    <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>Your answer here!</i></p>\n",
    "    \n",
    "- Is it invariant to scale? If not, how can we turn this method into it?\n",
    "\n",
    "    <p style=\"margin: 4px 0px 0px 5px; color:blue\"><i>Your answer here!</i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.3.2 Co-ocurrence matrix <a id=\"6232\"></a>\n",
    "\n",
    "Another technique also obtaining a statistical representation of the texture within a region is the **co-ocurrence matrix**, a square matrix $A(i,j)$ in which:\n",
    "\n",
    "- $i$ and $j$ represent intensity values (e.g. 0 to 255). \n",
    "- The entry $a_{ij}$ indicates how many times the intensity $i$ co-occurs with intensity $j$ in some designated spatial relationships $P$ (texture pattern). \n",
    "- $P$ is given by a displacement vector $d = [dr, dc]$, where $dr$ and $dc$ are the displacement in rows and columns, respectively.\n",
    "\n",
    "<center><img src=\"./images/co-ocu.png\" width=\"650\"/></center>\n",
    "\n",
    "The issue with this approach is how to select the appropriate displacement $d$. Once the co-ocurrence matrix of a region has been computed, a number of features can be extracted from it:\n",
    "\n",
    "- **Maximum probability:** gives us the strongest response to the texture pattern $P$$ \\\\[1pt]$\n",
    "\n",
    "$\\hspace{2cm} max_{ij}\\ c_{ij}$\n",
    "\n",
    "- **Energy:** minimum when all the entries $c_{ij}$ are identical (maximum uniformity)$ \\\\[1pt]$\n",
    "\n",
    "$\\hspace{2cm} \\sum_{i=0}^{255}\\sum_{j=0}^{255}\\ c_{ij}^2$\n",
    "\n",
    "- **Entropy:** measure randomness. Maximum value when all the entries $c_{ij}$ are identical (maximum entropy  $\\rightarrow$ minimum energy)$ \\\\[1pt]$\n",
    "\n",
    "$\\hspace{2cm} -\\sum_{i=0}^{255}\\sum_{j=0}^{255}\\ c_{ij} \\ logc_{ij}$\n",
    "\n",
    "- **Order k central moment**$ \\\\[1pt]$\n",
    "\n",
    "$\\hspace{2cm} \\sum_{i=0}^{255}\\sum_{j=0}^{255}\\ (i-j)^k \\ c_{ij}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\"><b><i>ASSIGNMENT 6: Computing co-ocurrence matrices</i></b></span>**\n",
    "\n",
    "Let's implement the method `co_ocurrence_matrix_features()`, which has to compute the normalized co-ocurrence matrix of `image` using the displacement vector `[dr,dc]` and normalizes it, obtaining `C(i,j)`. Note that `dr` and `dc` may take positive or negative values. Thereby, it takes as inputs:\n",
    "- an image, \n",
    "- a 2-size displacement vector, and \n",
    "- a number of central moments to compute. \n",
    "\n",
    "and returns:\n",
    "- a feature vector with size 3 + `n_moments` being: [`max_prob`, `energy`, `entropy`, `moments` (optional)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 6\n",
    "\n",
    "def co_ocurrence_matrix_features(image, d, n_moments):\n",
    "    \"\"\" Compute features from a image using a co-ocurrence matrix.   \n",
    "    \n",
    "        Args:\n",
    "            image: Binary image\n",
    "            d: displacement vector\n",
    "            n_moments: number of moment to be computed\n",
    "                    \n",
    "        Returns: \n",
    "            features: feature vector\n",
    "    \"\"\"   \n",
    "    \n",
    "    (n_r, n_c) = image.shape\n",
    "    co = np.zeros((256,256))\n",
    "    features = np.zeros(3+n_moments)\n",
    "    \n",
    "    # Compute image ranges to iterate from displacement vector\n",
    "    \n",
    "    if d[0] >= 0:\n",
    "        range_rows = range(0, n_r-d[0], 1)\n",
    "    else:\n",
    "        range_rows = range(-d[0], n_r, 1)\n",
    "\n",
    "    if d[1] >= 0:\n",
    "        range_columns = range(0, n_c-d[1], 1)\n",
    "    else:\n",
    "        range_columns = range(-d[1], n_c, 1)\n",
    "\n",
    "    # Compute co-ocurrence matrix    \n",
    "    for r in range_rows:\n",
    "        for c in range_columns:\n",
    "\n",
    "            i = image[r,c]\n",
    "            j = image[r+d[0],c+d[1]]\n",
    "\n",
    "            co[i,j] += 1\n",
    "\n",
    "    # Normalize co-ocurrence matrix\n",
    "    co = co/np.sum(co)\n",
    "\n",
    "    # Maximum probability\n",
    "    features[0] = None\n",
    "\n",
    "    # Energy\n",
    "    features[1] = None\n",
    "\n",
    "    # Entropy\n",
    "    mask = np.where(co!=0, True, False)\n",
    "    features[2] = None\n",
    "\n",
    "    # Central moments\n",
    "    for k in range(n_moments):\n",
    "        moment = 0\n",
    "        for i in range(co.shape[0]):\n",
    "            for j in range(co.shape[1]):\n",
    "                moment += ((None-None)**None)*co[None,None]\n",
    "                \n",
    "        features[3+k] = moment\n",
    "        \n",
    "    return np.round(features,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the next code to **test if the results are right**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "image = np.array([[10,60,20],[60,22,74],[72,132,2]], dtype=np.uint8)\n",
    "\n",
    "features = co_ocurrence_matrix_features(image,d=[1,-2],n_moments=4)\n",
    "\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>**Expected output: </font>**\n",
    "\n",
    "    [0.5  0.5  0.693  1.  -19.  802.  -31996.  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\"><b><i>ASSIGNMENT 7: Studying the invariance of co-occurence matrices</i></b></span>**\n",
    "\n",
    "Compare the results returned by `co_ocurrence_matrix_features()` when using the original image `hawaii.jpg`, with those returned by a rotated or scaled version of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 7\n",
    "\n",
    "# Read image and compute co-occurence matrix features\n",
    "image = cv2.imread(images_path + 'hawaii.jpg',0)\n",
    "features = co_ocurrence_matrix_features(None,d=[1,-2],n_moments=4)\n",
    "\n",
    "# Rotate image and compute co-occurence matrix features\n",
    "image_rotated = np.rot90(None)\n",
    "features_rotated = co_ocurrence_matrix_features(None,d=[1,-2],n_moments=4)\n",
    "    \n",
    "# Resize image and compute co-occurence matrix features\n",
    "image = cv2.resize(None, dsize=None, fx=None, fy=None) # keep the dsize=None\n",
    "features_scaled = co_ocurrence_matrix_features(None,d=[1,-2],n_moments=4)\n",
    "\n",
    "# Compare results\n",
    "print(\"Features original \", features,\"\\n Features rotated \", features_rotated, \"\\n Features scaled \", features_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"><b><i>Thinking about it (6)</i></b></font>\n",
    "\n",
    "Now, **answer the following question:**\n",
    "\n",
    "- **Compare the invariance of each feature in the feature vector** and **comment why it is invariant or not to rotation and scale.**\n",
    "\n",
    "    <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>Your answer here!</i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Awesome! This was a laborious and dense notebook, but you carried it through to the end!\n",
    "\n",
    "In this notebook you have learned:\n",
    "\n",
    "- how to compute non-central, central, scale-invariant and Hu moments for describing a region, and apply them to the plate number recognition problem.\n",
    "\n",
    "- how to describe textures using 1D moments of the histogram and co-ocurrence matrices, using them in the context of the state identification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra\n",
    "\n",
    "Usually, the co-ocurrence matrices **of the image rotated** 45, 90, and 135 degrees are also calculated. **What do you think this is due to?**  \n",
    "\n",
    "**Implement this new procedure** for co-ocurrence matrices and then, check again the invariances. **What happened?**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "382.85px",
    "left": "1390px",
    "right": "20px",
    "top": "120px",
    "width": "443px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
