{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.2 Clustering-based techniques for image segmentation\n",
    "\n",
    "In the previous notebook we had fun with contour based techniques for image segmentation. In this one we will play with region-based techniques, where the resulting segments cover the entire image. Concretely we will address two popular region-based methods: \n",
    "\n",
    "- K-means (<a href=\"#521\">section 5.2.1</a>)\n",
    "- Expectation-Maximization (EM, <a href=\"#522\">section 5.2.2</a>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem context - Color quantization\n",
    "\n",
    "<img src=\"./images/color-quantization.jpg\" width=\"800\"/>$\\\\[5pt]$\n",
    "\n",
    "Color quantization is the process of reducing the number of distinct colors in an image while preserving its color appearance as much as possible. It has many applications, like image compression (e.g. GIFs, which only support 256 colors!), [content-based image retrieval](https://en.wikipedia.org/wiki/Content-based_image_retrieval), edge detection and segmentation preprocessing, printing, medical imaging, etc. \n",
    "\n",
    "Image segmentation techniques can be used to achieve color quantization, let's see how it works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import scipy.stats as stats\n",
    "from ipywidgets import interact, fixed, widgets\n",
    "matplotlib.rcParams['figure.figsize'] = (10.0, 10.0)\n",
    "images_path = './images/'\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from utils.PlotEllipse import PlotEllipse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2.1 K-Means <a id=\"521\"></a>\n",
    "\n",
    "As commented, region-based techniques try to group together pixels that are similar. Such issue is often called the *clustering problem*. Different attributes can be used to decide if two pixels are similar or not: intensity, texture, color, pixel location, etc.\n",
    "\n",
    "The **k-means algorithm** is a region-based technique that, given a set of elements (image pixels in our case), makes $K$ clusters out of them. Thereby, it is a perfect technique for addressing color quantization, since our goal is to reduce the color palette of an image to a fixed number of colors $K$. Concretely, k-means aims to minimize the sum of squared Euclidean distances between points $x_i$ in a given space (*e.g.* grayscale or RGB color representations) and their nearest cluster centers $m_k$:\n",
    "\n",
    "$$\n",
    "\\underset{M}{\\arg\\min} D(X,M) = \\Sigma_{\\text{Cluster }k} \\Sigma_{\\text{point } i \\text{ in cluster } k} (x_i - m_k)^2\n",
    "$$\n",
    "\n",
    "In our case, the point $x_i$ could be interpreted as a **feature vector** describing the $i^{th}$ pixel that, as mentioned, could include information like the pixel color, intensity, texture, etc. Thus, $m_k$ represents **the mean of the feature vector** of the pixels in cluster $k$. \n",
    "\n",
    "Let's see how the k-means algorithm works in a color domain, where each pixel is represented in a feature n-dimensional space (*e.g.* grayscale images define a 1D feature space, while RGB images a 3D space):\n",
    "\n",
    "1. Pick the number $K$, that is, the number of clusters in which the image will be segmented (e.g. number of colors).\n",
    "2. Place $K$ centroids $m_k$ in the color space (e.g. randomly), these are the centers of the regions. \n",
    "3. Each pixel is assigned to the cluster with the closest centroid, hence creating new clusters. \n",
    "\n",
    "<center>\n",
    "    <img src=\"./images/kmeans-step-1.png\" width=\"400\"/>\n",
    "    <figcaption>Fig 1. Example in a 2D space (e.g. YCbCr color space) with 3 clusters. Each point is assigned to its closest centroid</figcaption>\n",
    "</center>$\\\\[5pt]$\n",
    "\n",
    "4. Compute the new means $m_k$ of the $K$ clusters. \n",
    "\n",
    "<center>\n",
    "<img src=\"./images/kmeans-step-2.png\" width=\"400\" align=\"center\"/>\n",
    "    <figcaption>Fig 2. Example of how the centroids evolve over time</figcaption>\n",
    "</center>$\\\\[5pt]$\n",
    "\n",
    "5. Repeat steps 3 and 4 until convergence, that is, some previously defined criteria is fulfilled (*e.g.* the centers of regions do not move, or a certain number of iterations is reached).$\\\\[10pt]$\n",
    "\n",
    "<center>\n",
    "    <img src=\"./images/kmeans-step-3.png\" width=\"400\" align=\"center\"/>\n",
    "    <figcaption>Fig 3. Final segmentation result</figcaption>\n",
    "</center>$\\\\[5pt]$\n",
    "\n",
    "This procedure is the same independently of the number of dimensions in the workspace. \n",
    "\n",
    "This technique presents a number of pros and cons:\n",
    "\n",
    "- **Pros:**\n",
    "  - It's simple.\n",
    "  - Convergence to a local minima is guaranteed (but no guarantee to reach the global minima).\n",
    "- **Cons:**\n",
    "  - High usage of memory.\n",
    "  - The K must be fixed.\n",
    "  - Sensible to the selection of the initialization (initial position of centroids).\n",
    "  - Sensible to outliers.\n",
    "  - Circular clusters in the feature space are assumed (because of the usage of the Euclidean distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means toy example\n",
    "\n",
    "Luckily for us, OpenCV defines a method that perform k-means: [`cv2.kmeans()`](https://docs.opencv.org/master/d5/d38/group__core__cluster.html#ga9a34dc06c6ec9460e90860f15bcd2f88), [here you can find a nice explanation](https://docs.opencv.org/master/d1/d5c/tutorial_py_kmeans_opencv.html) about how to use it. Let's take a look at a toy 1D k-means example in order to get familiar with it. The following function, `binarize_kmeans()`, binarizes an input `image` by executing the K-means algorithm, where the `it` sets its maximum number of iterations. \n",
    "\n",
    "Note that the stopping criteria can be either:\n",
    "- if a maximum number of iterations is reached, or \n",
    "- if the centroid moved less than a certain `epsilon` value in an iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_kmeans(image,it):\n",
    "    \"\"\" Binarize an image using k-means.   \n",
    "\n",
    "        Args:\n",
    "            image: Input image\n",
    "            it: K-means iteration\n",
    "    \"\"\"    \n",
    "    \n",
    "    # Set random seed for centroids \n",
    "    cv2.setRNGSeed(124)\n",
    "    \n",
    "    # Flatten image\n",
    "    flattened_img = image.reshape((-1,1))\n",
    "    flattened_img = np.float32(flattened_img)\n",
    "    \n",
    "    #Set epsilon\n",
    "    epsilon = 0.2\n",
    "    \n",
    "    # Estabish stopping criteria (either `it` iterations or moving less than `epsilon`)\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, it, epsilon)\n",
    "    \n",
    "    # Set K parameter (2 for thresholding)\n",
    "    K = 2\n",
    "    \n",
    "    # Call kmeans using random initial position for centroids\n",
    "    _,label,center=cv2.kmeans(flattened_img,K,None,criteria,it,cv2.KMEANS_RANDOM_CENTERS)\n",
    "    \n",
    "    # Colour resultant labels\n",
    "    center = np.uint8(center) # Get center coordinates as unsigned integers   \n",
    "    print(center)\n",
    "    flattened_img = center[label.flatten()] # Get the color (center) assigned to each pixel\n",
    "    \n",
    "    # Reshape vector image to original shape\n",
    "    binarized = flattened_img.reshape((image.shape))\n",
    "    \n",
    "    # Show resultant image\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.title(\"Original image\")\n",
    "    plt.imshow(binarized, cmap='gray',vmin=0,vmax=255)\n",
    "    \n",
    "    # Show how original histogram have been segmented\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.title(\"Segmented histogram\")\n",
    "    plt.hist([image[binarized==center[0]].ravel(), image[binarized==center[1]].ravel()],256,[0,256], color=[\"black\",\"gray\"],stacked=\"true\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, [`cv2.kmeans()`](https://docs.opencv.org/2.4/modules/core/doc/clustering.html) returns two relevant arguments:\n",
    "\n",
    "- label: Integer array that stores the cluster index for every pixel.\n",
    "- center: Matrix containing the cluster centroids (each row represents a different centroid).\n",
    "\n",
    "**Attention to this!!!** It is also remarkable the first function argument, which represents the data for clustering: an array of N-Dimensional points with float coordinates. Such array has the shape $num\\_samples \\times num\\_features$, i.e., it has as many rows as samples (pixels in the image), and as many columns as features describing those samples (for example, if using the intensity of a pixel in a graysacle image, there is only one feature). For that, the code line `image.reshape((-1,1))` convert the initial grayscale image with dimensions $242\\times 1133$ into a flattened version of it with dimension $274186\\times 1$, that is, 274186 samples (or pixels) with only one feature, its intensity. Take a look at [`np.reshape()`](https://numpy.org/doc/stable/reference/generated/numpy.reshape.html) to see how it works. \n",
    "\n",
    "Below it is provided an interactive code so you can play with `cv2.kmeans()` by calling it with different `it`values. \n",
    "\n",
    "*As you can see, if k=2 in a grayscale image, it is a binarization method that doesn't need to fix a manual threshold. We could have used it, for example, when dealing with the plate recognition problem!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['figure.figsize'] = (10.0, 10.0)\n",
    "\n",
    "image = cv2.imread(images_path + 'plate.jpg',0)\n",
    "\n",
    "interact(binarize_kmeans, image=fixed(image),it=(2,5,1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that for 1D spaces and not high-resolution images k-means is very fast! (it only needs a few iterations to converge). What happens if k-means is applied to color images (3D space) in order to get color quantization?  \n",
    "\n",
    "Now that you know how k-means works, you can experimentally answer such question!  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  **<span style=\"color:green\"><b><i>ASSIGNMENT 1: Playing with K-means</i></b></span>**\n",
    "\n",
    "Write an script that:\n",
    "- applies k-means to `malaga.png` with different values for $K$: $K=4$, $K=8$ and $K=16$, setting `epsilon=0.2` and `it=10` as convergence criteria, and \n",
    "- shows, in a $2\\times2$ subplot, the 3 resulting images along with the input one.\n",
    "\n",
    "Notice that in this case we are using 3 features per pixel, their R, G and B values, so the input data for the kmeans function has the dimensions $num\\_pixels \\times 3$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>**Expected output:**  </font>\n",
    "\n",
    "<img src=\"images/exercise1.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 1\n",
    "matplotlib.rcParams['figure.figsize'] = (15.0, 12.0)\n",
    "\n",
    "# Read RGB image\n",
    "image = cv2.imread(images_path + \"malaga.png\")\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Flatten image\n",
    "flattened_img = image.reshape((None,None))\n",
    "flattened_img = np.float32(flattened_img)\n",
    "\n",
    "# Set criteria\n",
    "it = None\n",
    "epsilon = None\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, it, epsilon)\n",
    "\n",
    "# Apply k-means. Keep the third argument as None!\n",
    "_,label4,center4=cv2.kmeans(None,None,None,None,30,cv2.KMEANS_RANDOM_CENTERS)\n",
    "_,label8,center8=cv2.kmeans(None,None,None,None,30,cv2.KMEANS_RANDOM_CENTERS)\n",
    "_,label16,center16=cv2.kmeans(None,None,None,None,30,cv2.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "# Colour resultant labels\n",
    "center4 = np.uint8(center4)\n",
    "center8 = np.uint8(center8)\n",
    "center16 = np.uint8(center16)\n",
    "\n",
    "# Get the color (center) assigned to each pixel\n",
    "res4 = center4[None]\n",
    "res8 = center8[None]\n",
    "res16 = center16[None]\n",
    "\n",
    "# Reshape to original shape\n",
    "quantized4 = res4.reshape((image.shape))\n",
    "quantized8 = res8.reshape((image.shape))\n",
    "quantized16 = res16.reshape((image.shape))\n",
    "\n",
    "# Show original image\n",
    "plt.subplot(2,2,1)\n",
    "plt.title(\"Original image\")\n",
    "plt.imshow(None)\n",
    "\n",
    "# Show k=4\n",
    "plt.subplot(2,2,2)\n",
    "plt.title(\"k=4\")\n",
    "plt.imshow(None)\n",
    "\n",
    "# Show k=8\n",
    "plt.subplot(2,2,3)\n",
    "plt.title(\"k=8\")\n",
    "plt.imshow(None)\n",
    "\n",
    "# Show k=16\n",
    "plt.subplot(2,2,4)\n",
    "plt.title(\"k=16\")\n",
    "plt.imshow(None);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"><b><i>Thinking about it (1)</i></b></font>\n",
    "\n",
    "Now, **answer the following questions**:\n",
    "\n",
    "- What `cv2.kmeans()` is doing in each iteration?\n",
    "\n",
    "    <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>Your answer here!</i></p>\n",
    "\n",
    "- What number of maximum iterations did you use? Why?\n",
    "  \n",
    "    <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>Your answer here!</i></p>\n",
    "    \n",
    "- How could we compress these images so they require less space in memory? *Note: consider that a pixel in RGB needs 3 bytes to be represented, 8 bits per band.*\n",
    "  \n",
    "    <p style=\"margin: 4px 0px 0px 5px; color:blue\"><i>Your answer here!</i></p>   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  **<span style=\"color:green\"><b><i>Analyzing execution times</i></b></span>**\n",
    "\n",
    "In this exercise you are asked to compare the execution time of K-means in a grayscale image, with K-means in a RGB image. Use the image `malaga.png` for this task, and use the same number of clusters and criteria for both, the grayscale and the RGB images.\n",
    "\n",
    "*Tip: [how to measure execution time in Python](https://stackoverflow.com/questions/14452145/how-to-measure-time-taken-between-lines-of-code-in-python)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "print(\"Measuring the execution time needed for ...\")\n",
    "\n",
    "K = 2\n",
    "\n",
    "# Read images\n",
    "image = cv2.imread(images_path + \"malaga.png\")\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "# Set criteria\n",
    "it = None\n",
    "epsilon = None\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, it, epsilon)\n",
    "\n",
    "start = time.process_time() # Start timer\n",
    "\n",
    "# Flatten image\n",
    "flattened_img = image.reshape((None,None))\n",
    "flattened_img = np.float32(flattened_img)\n",
    "\n",
    "# Apply k-means\n",
    "_,label,center=cv2.kmeans(None,None,None,None,30,cv2.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "print(\"K-means in the RGB image:\", round(time.process_time() - start,5), \"seconds\") # Stop timer\n",
    "\n",
    "start = time.process_time() # Start timer\n",
    "\n",
    "# Flatten image\n",
    "flattened_img = gray.reshape((None,None))\n",
    "flattened_img = np.float32(flattened_img)\n",
    "\n",
    "# Apply k-means\n",
    "_,label,center=cv2.kmeans(None,None,None,None,30,cv2.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "print(\"K-means in the grayscale image:\", round(time.process_time() - start,5), \"seconds\") # Stop timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2.2 Expectation-Maximization (EM) <a id=\"522\"></a>\n",
    "\n",
    "**Expectation-Maximization (EM)** is the generalization of the K-means algorithm, where each cluster is represented by a Gaussian distribution, parametrized by a mean and a covariance matrix, instead of just a centroid. It's a *soft clustering* since it doesn't give *hard* decisions where a pixel belongs or not to a cluster, but the probability of that pixel belonging to each cluster $C_j$, that is, $p(x|C_j) \\sim N(\\mu_j,\\Sigma_j)$. This implies that at each algorithm iteration not just the mean of each cluster is refined (as in K-means), but also their covariance matrices.\n",
    "\n",
    "Before going into detail on the theory behind EM, it is worth seeing how it performs in the car plate problem. OpenCV provides a class implementing the needed functionality for applying EM segmentation to an image, called [`cv2.ml.EM()`](https://docs.opencv.org/3.4/d1/dfb/classcv_1_1ml_1_1EM.html). All methods and parameters are fully detailed in the documentation, so it is a good idea to take a look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['figure.figsize'] = (10.0, 10.0)\n",
    "cv2.setRNGSeed(5)\n",
    "\n",
    "# Define parameters\n",
    "n_clusters = 2 \n",
    "covariance_type = 0 # 0: covariance matrix spherical. 1: covariance matrix diagonal. 2: covariance matrix generic\n",
    "n_iter = 10\n",
    "epsilon = 0.2\n",
    "\n",
    "# Create EM empty object\n",
    "em = cv2.ml.EM_create()\n",
    "\n",
    "# Set parameters\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, n_iter, epsilon)\n",
    "em.setClustersNumber(n_clusters)\n",
    "em.setCovarianceMatrixType(covariance_type)\n",
    "em.setTermCriteria(criteria)\n",
    "\n",
    "# Read grayscale image\n",
    "image = cv2.imread(images_path + \"plate.jpg\",0)\n",
    "\n",
    "# Flatten image\n",
    "flattened_img = image.reshape((-1,1))\n",
    "flattened_img = np.float32(flattened_img)\n",
    "\n",
    "# Apply EM\n",
    "_, _, labels, _ = em.trainEM(flattened_img)\n",
    "\n",
    "# Reshape labels to image size (binarization)\n",
    "binarized = labels.reshape((image.shape))\n",
    "\n",
    "# Show original image\n",
    "plt.subplot(2,1,1)\n",
    "plt.title(\"Binarized image\")\n",
    "plt.imshow(binarized, cmap=\"gray\")\n",
    "\n",
    "# --------------- Gaussian visualization ---------------\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.title(\"Probabilities of the clusters\")\n",
    "\n",
    "# Get means and covs (for grayscale 1D both)\n",
    "means = em.getMeans()\n",
    "covs = em.getCovs()\n",
    "\n",
    "# Get standard deviation as numPy array\n",
    "sigmas = np.sqrt(covs)\n",
    "sigmas = sigmas[:,0,0]\n",
    "\n",
    "# Cast list to numPy array\n",
    "means = np.array(means)[:,0]\n",
    "\n",
    "# Plot Gaussians\n",
    "x = np.linspace(0, 256, 100)\n",
    "plt.plot(x, stats.norm.pdf(x, loc = means[0], scale = sigmas[0]))\n",
    "plt.plot(x, stats.norm.pdf(x, loc = means[1], scale = sigmas[1]))\n",
    "plt.legend(['Black Region', 'White Region'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, although in OpenCV k-means is implemented as a method and EM as a class, they operate in a similar way. In the example above, we are segmenting a car plate into two clusters, and **each cluster is defined by a Gaussian distribution** (a Gaussian distribution for the black region, and another one for the white region). This is the basis of EM, **but how it works**?  \n",
    "\n",
    "EM is an iterative algorithm that is divided into two main steps:\n",
    "\n",
    "- First of all, it **initializes the mean and covariance matrix of each of the $K$ clusters**. Typically, it picks at random ($\\mu_j$,$\\Sigma_j$) and $P(C_j)$ (prior probability) for each cluster $j$.\n",
    "- Then, it keeps iterating doing Expectation-Maximization steps until some stopping criteria is satisfied (e.g. when no change occurs in a complete iteration):$\\\\[1pt]$\n",
    "    1. **Expectation step:** calcule the probabilities of every point belonging to each cluster, that is $p(C_j|x_i), \\forall i \\in data$:\n",
    "    $$P(C_j|x_i)=\\frac{p(x_i|C_j)p(C_j)}{p(x_i)}=\\frac{p(x_i|C_j)p(C_j)}{\\sum_i P(x_i|C_j)p(C_j)}$$\n",
    "    \n",
    "    assign $x_i$ to the cluster $C_j$ with the highest probability $P(C_j|x_i)$.$\\\\[10pt]$\n",
    "    2. **Maximization step:** re-estimate the cluster parameters (($\\mu_j$,$\\Sigma_j$) and $p(C_j)$) for each cluster $j$ knowing the expectation step results, which is also called *Maximum Likelihood Estimate* (MLE):\n",
    "$$\\mu_j=\\frac{\\sum_i p(C_j|x_i)x_i}{\\sum_i p(C_j|x_i)}$$ $\\\\[5pt]$\n",
    "$$\\sum_j = \\frac{\\sum_i p(C_j|x_i)(x_i-\\mu_j)(x_i-\\mu_j)^T}{\\sum_i p(C_j|x_i)}$$$\\\\[5pt]$\n",
    "$$p(C_j)=\\sum_i p(C_j|x_i)p(x_i)=\\frac{\\sum_i p(C_j|x_i)}{N}$$    \n",
    "    Note that if no other information is available, the priors are considered equally probable.\n",
    "    \n",
    "<center>\n",
    "    <img src=\"./images/em.gif\" width=\"400\" align=\"center\">\n",
    "    <figcaption>Fig 4. Example of an execution of the EM algorithm with two clusters, with details about the evolution of their associated Gaussian distributions.</figcaption>\n",
    "</center>$\\\\[5pt]$\n",
    "\n",
    "\n",
    "Doesn't it remind you to the K-means algorithm? **What is the difference between them?** \n",
    "\n",
    "The main difference is that K-means employs the **euclidian distance** to measure how near is a point to a cluster. In EM we use a distance in which **each dimension is weighted** by the **covariance matrix** of each cluster, which is also called **Mahalanobis distance**. Furthermore, for k-means a point of data **belongs or not to** a cluster, in EM a point of data have a higher or lower **probability** to belong to a cluster. The table below summarizes other differences:\n",
    "\n",
    "<table width=\"500px\">\n",
    "    <tr>\n",
    "        <td style=\"text-align:center;\"></td>\n",
    "        <td style=\"text-align:center;\"><b>K-means</b></td>\n",
    "        <td style=\"text-align:center;\"><b>EM</b></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:center;\"><b>Cluster representation</b></td>\n",
    "        <td style=\"text-align:center;\">Mean</td>\n",
    "        <td style=\"text-align:center;\">Mean, (co)variance</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:center;\"><b>Cluster initialization</b></td>\n",
    "        <td style=\"text-align:center;\">Randomly select K means</td>\n",
    "        <td style=\"text-align:center;\">Initialize K Gaussian <br />distributions ($\\mu_j$,$\\Sigma_j$) and $P(C_j)$</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:center;\"><b>Expectation:</b> <br />\n",
    "Estimate the cluster of each data</td>\n",
    "        <td style=\"text-align:center;\">Assign each point to the closest mean </td>\n",
    "        <td style=\"text-align:center;\">Compute $P(C_j|x_i)$</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:center;\"><b>Maximization:</b> <br /> Re-estimate the cluster parameters</td>\n",
    "        <td style=\"text-align:center;\">Compute means of current clusters</td>\n",
    "        <td style=\"text-align:center;\">Compute new ($\\mu_j,\\Sigma_j$), $P(C_j)$ for each cluster $j$</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "If you still curious about EM, you can find [here](https://www.youtube.com/watch?v=REypj2sy_5U) a more detailed explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"orange\">OpenCV pill</font>\n",
    "\n",
    "Going back to code, working with EM we have to specify a covariance matrix type using [`em.setCovarianceMatrixType()`](https://docs.opencv.org/3.4/d1/dfb/classcv_1_1ml_1_1EM.html#a8b383c62697eac9a972931674790f6cd). Also, when you applying [`em.trainEM()`](https://docs.opencv.org/3.4/d1/dfb/classcv_1_1ml_1_1EM.html#a5a6a7badbc0c85a8c9fa50a41bf1bcd2) it doesn't return the centroid of the clusters, it is possible to get them calling [`em.getMeans()`](https://docs.opencv.org/3.4/d1/dfb/classcv_1_1ml_1_1EM.html#acec62dd55c06711c81d741c2d96603d1). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\"><b><i>ASSIGNMENT 2: Color quantization with YCrCb color space</i></b></span>**\n",
    "\n",
    "In the next example, color quantization is realized using the YCrCb color space instead of RGB. Recall that you have more info about such a space available in [Apendix 12.2 Color spaces](../Chapter%2012.%20Appendices/12.2%20Color%20spaces.ipynb). In this way, color quantization is only applied to the two color bands Cr and Cb, neglecting the grayscale one Y. \n",
    "\n",
    "Notice that in this case, the feature space has 2 dimensions, one for the Cr band, and another dimension for the Cb, hence the feature vector describing the $i^{th}$ pixel results $x_i = [Cr_i,Cb_i]$. \n",
    "\n",
    "Let's see how it works!\n",
    "\n",
    "**What to do?** Test and understand the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 2\n",
    "matplotlib.rcParams['figure.figsize'] = (15.0, 15.0)\n",
    "cv2.setRNGSeed(5)\n",
    "\n",
    "# Define parameters\n",
    "\n",
    "n_clusters = 3 # Don't modify this parameter for this exercise\n",
    "\n",
    "covariance_type = 1 # 0: Spherical covariance matrix. 1: Diagonal covariance matrix. 2: Full covariance matrix\n",
    "n_iter = 10\n",
    "epsilon = 0.2\n",
    "\n",
    "# Create EM empty object\n",
    "em = cv2.ml.EM_create()\n",
    "\n",
    "# Set parameters\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, n_iter, epsilon)\n",
    "em.setClustersNumber(n_clusters)\n",
    "em.setCovarianceMatrixType(covariance_type)\n",
    "em.setTermCriteria(criteria)\n",
    "\n",
    "# Read color image\n",
    "image = cv2.imread(images_path + \"malaga.png\")\n",
    "\n",
    "# Convert to YCrCb\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)\n",
    "\n",
    "# Take color bands (2 lasts)\n",
    "color_bands = image[:,:,1:3]\n",
    "\n",
    "# Flatten image\n",
    "flattened_img = color_bands.reshape((-1,2))\n",
    "flattened_img = np.float32(flattened_img)\n",
    "\n",
    "# Apply EM\n",
    "_, _, labels, _ = em.trainEM(flattened_img)\n",
    "\n",
    "# Colour resultant labels\n",
    "centers = em.getMeans()\n",
    "centers = np.uint8(centers)\n",
    "res = centers[labels.flatten()]\n",
    "\n",
    "# Reshape to original shape\n",
    "color_bands = res.reshape((image.shape[0:2]) + (2,))\n",
    "\n",
    "# Merge original first band with quantized color bands\n",
    "quantized = np.zeros(image.shape)\n",
    "quantized[:,:,0] = image[:,:,0]\n",
    "quantized[:,:,[1,2]] = color_bands\n",
    "\n",
    "# Cast to unsigned data dype\n",
    "quantized = np.uint8(quantized)\n",
    "\n",
    "# Reconvert to RGB\n",
    "quantized_rgb = cv2.cvtColor(quantized, cv2.COLOR_YCrCb2RGB)\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_YCrCb2RGB)\n",
    "\n",
    "# Show original image\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Original image\")\n",
    "plt.imshow(image_rgb)\n",
    "\n",
    "# Show resultant image\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"YCrCb quantized colors (3 colors)\")\n",
    "plt.imshow(quantized_rgb);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"><b><i>Thinking about it (2)</i></b></font>\n",
    "\n",
    "Once you understanded the code above, **answer the following questions:**\n",
    "\n",
    "- What are the dimensions of the means $u_j$ and the covariance matrices $\\Sigma_j$?\n",
    "\n",
    "    <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>Your answer here!</i></p>\n",
    "    \n",
    "- What are the dimensions of the input to `trainEM()`? Why?\n",
    "\n",
    "    <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>Your answer here!</i></p>\n",
    "\n",
    "- Why are the obtained results so good using only 3 clusters?\n",
    "  \n",
    "    <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>Your answer here!</i></p>\n",
    "    \n",
    "- What compression would be better in terms of space in memory, a 16-color compression in a RGB image (that is, each band uses 16 different colors instead of the original 256) or a 4-color compression in a YCrCb image? *Hint: consider the bits needed to codify such information. Hint 2: the grayscale band in YCrCb, that is, Y, is not compressed.*\n",
    "  \n",
    "    <p style=\"margin: 4px 0px 0px 5px; color:blue\"><i>Your answer here!</i></p>   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diving deeper into covariance matrices\n",
    "\n",
    "There are 3 types of covariance matrices: **spherical covariances**, **diagonal covariances** or **full covariances**: $\\\\[10pt]$\n",
    "\n",
    "<center>\n",
    "<img src=\"./images/ellipses.png\" width=\"700\" align=\"center\">\n",
    "    <figcaption>Fig 5. Examples of different types of covariance matrices.</figcaption>$\\\\[10pt]$ \n",
    "</center>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  **<span style=\"color:green\"><b><i>ASSIGNMENT 3: Visualizing clusters from EM</i></b></span>**\n",
    "\n",
    "Next, you have a code for visualizing the clusters in the YCrCb color space using EM.  \n",
    "\n",
    "**What to do?** Run the previous example modifying the type of covariance in the EM algorithm and visualize the changes using the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 3\n",
    "matplotlib.rcParams['figure.figsize'] = (10.0, 10.0)\n",
    "\n",
    "# Get means (2D) and covariance matrices (2x2)\n",
    "means = np.array(em.getMeans())\n",
    "covs = np.array(em.getCovs())\n",
    "\n",
    "# Create figure\n",
    "fig, ax = plt.subplots()\n",
    "plt.axis([16, 240, 16, 240])\n",
    "\n",
    "# Get points contained in each cluster\n",
    "cluster_1 = np.any(color_bands == np.unique(res,axis=0)[0,:],axis=2)\n",
    "cluster_2 = np.any(color_bands == np.unique(res,axis=0)[1,:],axis=2)\n",
    "cluster_3 = np.any(color_bands == np.unique(res,axis=0)[2,:],axis=2)\n",
    "cluster_1 = image[cluster_1]\n",
    "cluster_2 = image[cluster_2]\n",
    "cluster_3 = image[cluster_3]\n",
    "\n",
    "# Plot them\n",
    "plt.plot(cluster_1[:,1],cluster_1[:,2],'go')\n",
    "plt.plot(cluster_2[:,1],cluster_2[:,2],'ro')\n",
    "plt.plot(cluster_3[:,1],cluster_3[:,2],'bo')\n",
    "\n",
    "# Plot ellipses representing covariance matrices\n",
    "PlotEllipse(fig, ax, np.vstack(means[0,:]), covs[0,:,:], 2, color='black')\n",
    "PlotEllipse(fig, ax, np.vstack(means[1,:]), covs[1,:,:], 2, color='black')\n",
    "PlotEllipse(fig, ax, np.vstack(means[2,:]), covs[2,:,:], 2, color='black')\n",
    "\n",
    "fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"><b><i>Thinking about it (3)</i></b></font>\n",
    "\n",
    "**Answer the following questions** about how clustering works in EM:\n",
    "\n",
    "- What are the differences between each type of covariance?\n",
    "  \n",
    "    <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>Your answer here!</i></p>\n",
    "    \n",
    "- What type of covariance makes EM equivalent to k-means?\n",
    "  \n",
    "    <p style=\"margin: 4px 0px 0px 5px; color:blue\"><i>Your answer here!</i></p>   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\"><b><i>ASSIGNMENT 4: Applying EM considering different color spaces</i></b></span>**\n",
    "\n",
    "It's time to show what you have learned about **EM** and **color spaces**!\n",
    "\n",
    "**What is your task?** You are asked to **compare color quantization in a RGB color space and in a YCrCb color space**.\n",
    "\n",
    "For that:\n",
    "- apply Expectation-Maximization to `malaga.png` using 4 clusters (colors) to both the RGB-space image and the YCrCb-space one,\n",
    "- and display both results along with the original image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>**Expected output:**  </font>\n",
    "\n",
    "<img src=\"images/exercise2.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 4\n",
    "matplotlib.rcParams['figure.figsize'] = (15.0, 12.0)\n",
    "cv2.setRNGSeed(5)\n",
    "\n",
    "# Define parameters\n",
    "n_clusters = 4\n",
    "covariance_type = 2 # 0: covariance matrix spherical. 1: covariance matrix diagonal. 2: covariance matrix generic\n",
    "n_iter = None\n",
    "epsilon = None\n",
    "\n",
    "# Create EM empty objects\n",
    "em = cv2.ml.EM_create()\n",
    "\n",
    "# Set parameters\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, n_iter, epsilon)\n",
    "\n",
    "em.setClustersNumber(n_clusters)\n",
    "em.setCovarianceMatrixType(covariance_type)\n",
    "em.setTermCriteria(criteria)\n",
    "\n",
    "# Read image\n",
    "image = cv2.imread(images_path + \"malaga.png\")\n",
    "\n",
    "# Convert image to RGB\n",
    "image_RGB = cv2.cvtColor(image, None)\n",
    "\n",
    "# Convert image to YCrCb\n",
    "image_YCrCb = cv2.cvtColor(image, None)\n",
    "\n",
    "# Flatten RGB image\n",
    "flattened_RGB = image_RGB.reshape((None,None))\n",
    "flattened_RGB = np.float32(flattened_RGB)\n",
    "\n",
    "# Flatten color bands of YCrCb image\n",
    "color_bands_YCrCb = image_YCrCb[:,:,1:3]\n",
    "flattened_YCrCb = color_bands_YCrCb.reshape((None,None))\n",
    "flattened_YCrCb = np.float32(flattened_YCrCb)\n",
    "\n",
    "# Apply EM and get centers of clusters\n",
    "_, _, labels_RGB, _ = em.trainEM(None)\n",
    "centers_RGB = em.getMeans()\n",
    "centers_RGB = np.uint8(centers_RGB)\n",
    "\n",
    "_, _, labels_YCrCb, _ = em.trainEM(None)\n",
    "centers_YCrCb = em.getMeans()\n",
    "centers_YCrCb = np.uint8(centers_YCrCb)\n",
    "\n",
    "# Colour resultant labels\n",
    "res_RGB = centers_RGB[labels_RGB.flatten()]\n",
    "res_YCrCb = centers_YCrCb[labels_YCrCb.flatten()]\n",
    "\n",
    "# Reshape to original shape\n",
    "quantized_RGB = res_RGB.reshape((image.shape))\n",
    "quantized_colors_YCrCb = res_YCrCb.reshape((image.shape[0:2]) + (2,))\n",
    "\n",
    "# Merge original first band with quantized color bands for YCrCb image\n",
    "quantized_YCrCb = np.zeros(image.shape)\n",
    "quantized_YCrCb[:,:,0] = image_YCrCb[:,:,0]\n",
    "quantized_YCrCb[:,:,[1,2]] = quantized_colors_YCrCb\n",
    "\n",
    "# Cast YCrCb image to unsigned data dype\n",
    "quantized_YCrCb = np.uint8(quantized_YCrCb)\n",
    "\n",
    "# Reconvert YCrCb image back to RGB\n",
    "quantized_YCrCb = cv2.cvtColor(quantized_YCrCb, cv2.COLOR_YCrCb2RGB)\n",
    "\n",
    "# Show original image\n",
    "plt.subplot(2,2,1)\n",
    "plt.title(\"Original image\")\n",
    "plt.imshow(None)\n",
    "\n",
    "# Show resultant quantization using RGB color space\n",
    "plt.subplot(2,2,2)\n",
    "plt.title(\"Quantized colors using RGB color space\")\n",
    "plt.imshow(None)\n",
    "\n",
    "# Show resultant quantization using YCrCb color space\n",
    "plt.subplot(2,2,4)\n",
    "plt.title(\"Quantized colors using YCrCb color space\")\n",
    "plt.imshow(None);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Congratulations for getting this work done! You have learned:\n",
    "\n",
    "- how k-means clustering works and how to use it,\n",
    "- how EM algorithm performs and how to employ it,\n",
    "- how to carry out color quantization and the importance of color spaces in this context, and\n",
    "- some basics for image compression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **<span style=\"color:green\"><b><i>OPTIONAL</i></b></span>**\n",
    "\n",
    "You have used YCrCb in this notebook because you were already fimiliar with it. The truth is that, in color quantization matters, [Lab color space](https://en.wikipedia.org/wiki/CIELAB_color_space) is commonly used.  \n",
    "\n",
    "Surf the internet for information about the Lab color space and then **answer the following questions**:\n",
    "\n",
    "- How does Lab color space work?\n",
    "- Why is it typically used for color quantization?\n",
    "\n",
    "### **<span style=\"color:green\"><b><i>END OF OPTIONAL PART</i></b></span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "<a name=\"myfootnote1\">[1]</a>: Borenstein, Eran, Eitan Sharon, and Shimon Ullman. [Combining top-down and bottom-up segmentation.](http://www.wisdom.weizmann.ac.il/~vision/courses/2006_2/papers/recog_seg/Borenstein%20combining%20top-down%20and%20bottom-up%20segmentation.pdf). IEEE Conference on Conference on Computer Vision and Pattern Recognition Workshop, 2004."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "855.85px",
    "left": "1494px",
    "right": "20px",
    "top": "116px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
